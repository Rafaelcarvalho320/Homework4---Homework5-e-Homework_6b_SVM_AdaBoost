{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafaelcarvalho320/Homework5-e-Homework_6b_SVM_AdaBoost/blob/main/Homework5_reso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Homework_5_SVMs**\n",
        "\n",
        "Arienilce Sacramento - 201706840081\n",
        "\n",
        "Rafael Carvalho - 201706840055\n",
        "\n",
        "Yasmim Miranda - 201906840010\n",
        "\n",
        "\n",
        "Dataset usado: estudante_201706840055"
      ],
      "metadata": {
        "id": "deR97J6C1aTz"
      },
      "id": "deR97J6C1aTz"
    },
    {
      "cell_type": "markdown",
      "id": "5d030a4e",
      "metadata": {
        "id": "5d030a4e"
      },
      "source": [
        "6) Use o scikit-learn para treinar uma SVM com kernel linear, usando hiperparâmetro: C=1.\n",
        "\n",
        "Neste caso use a versão normalizada dos dados, com os fatores de normalização projetados com base no conjunto de treino, para que este conjunto tenha média 0 e variância 1.\n",
        "\n",
        "a) Treine a SVM com o conjunto de treino indicado no arquivo dataset_train.txt.\n",
        "b) Indique o desempenho do modelo SVM no conjunto de teste dataset_test.txt. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06284de",
      "metadata": {
        "id": "a06284de"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6c0ca0",
      "metadata": {
        "id": "7c6c0ca0"
      },
      "outputs": [],
      "source": [
        "# Carregar o conjunto de treinamento\n",
        "df_train = pd.read_csv(r'C:\\Users\\Dell\\Documents\\SIGAA\\8º Semestre\\Inteligência Computacional\\estudante_201706840055_train.txt')\n",
        "\n",
        "\n",
        "# Converter o dataframe do pandas para uma matriz NumPy\n",
        "data_train = np.array(df_train)\n",
        "X_train = data_train[:, :-1]  \n",
        "y_train = data_train[:, -1]   \n",
        "\n",
        "# Carregar o conjunto de teste\n",
        "df_test = pd.read_csv(r'C:\\Users\\Dell\\Documents\\SIGAA\\8º Semestre\\Inteligência Computacional\\estudante_201706840055_test.txt')\n",
        "\n",
        "# Converter o dataframe do pandas para uma matriz NumPy\n",
        "data_test = np.array(df_test)\n",
        "X_test = data_test[:, :-1]  \n",
        "y_test = data_test[:, -1]   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f683e5f1",
      "metadata": {
        "id": "f683e5f1"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f084016c",
      "metadata": {
        "id": "f084016c"
      },
      "outputs": [],
      "source": [
        "svm_linear = SVC(kernel='linear', C=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "413c290e",
      "metadata": {
        "id": "413c290e",
        "outputId": "4d2358aa-cbb6-471b-b187-457d8f13ce09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=1, kernel='linear')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm_linear.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65194f45",
      "metadata": {
        "id": "65194f45"
      },
      "outputs": [],
      "source": [
        "X_test = sc.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1f0ccef",
      "metadata": {
        "id": "f1f0ccef"
      },
      "outputs": [],
      "source": [
        "y_pred = svm_linear.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e6123d",
      "metadata": {
        "id": "58e6123d",
        "outputId": "eb080c8d-9325-40e7-94b9-27cead061d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.50         4\n",
            "   macro avg       0.67      0.67      0.50         4\n",
            "weighted avg       0.83      0.50      0.50         4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53360e42",
      "metadata": {
        "id": "53360e42"
      },
      "source": [
        "c) Converta esta SVM para um perceptron, estime o custo computacional durante a fase de teste da SVM na forma original com sua versão implementada como perceptron. Indique se há algum ganho computacional em termos de memória e número de operações ao se converter essa SVM para um perceptron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e49a5ec",
      "metadata": {
        "id": "8e49a5ec",
        "outputId": "d3cbca0d-d73a-4292-9ca9-2f9de1dd37d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.50         4\n",
            "   macro avg       0.67      0.67      0.50         4\n",
            "weighted avg       0.83      0.50      0.50         4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(r'C:\\Users\\Dell\\Documents\\SIGAA\\8º Semestre\\Inteligência Computacional\\estudante_201706840055_train.txt')\n",
        "\n",
        "\n",
        "data_train = np.array(df_train)\n",
        "X_train = data_train[:, :-1] # Todas as colunas, exceto a última\n",
        "y_train = data_train[:, -1] # Última coluna, que contém os rótulos/classes\n",
        "\n",
        "\n",
        "df_test = pd.read_csv(r'C:\\Users\\Dell\\Documents\\SIGAA\\8º Semestre\\Inteligência Computacional\\estudante_201706840055_test.txt')\n",
        "\n",
        "\n",
        "data_test = np.array(df_test)\n",
        "X_test = data_test[:, :-1] # Todas as colunas, exceto a última\n",
        "y_test = data_test[:, -1] # Última coluna, que contém os rótulos/classes\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "\n",
        "perceptron = Perceptron()\n",
        "\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a399516",
      "metadata": {
        "id": "4a399516"
      },
      "source": [
        "O custo computacional durante a fase de teste da SVM depende do número de vetores de suporte e da dimensão do espaço de característica. Já a versão implementada como perceptron tem um custo computacional durante a fase de teste de O(d), independentemente do número de exemplos de treinamento ou do número de vetores de suporte.\n",
        "Em termos de memória, a SVM armazena todos os vetores de suporte, que podem ser um conjunto substancial de dados, enquanto o perceptron armazena apenas os pesos treinados, que geralmente são muito menores do que os vetores de suporte."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "689253ab",
      "metadata": {
        "id": "689253ab"
      },
      "source": [
        "7) Sobre o projeto de SVMs: \n",
        "a) Use o scikit-learn (exemplificado no código ak_svm.py) para treinar uma SVM com kernel Gaussiano (também chamado de “RBF”), usando o conjunto de validação para fazer o “tuning” (otimização) de dois hiperparâmetros: “C” e “gamma”, avaliando os valores: \n",
        "\n",
        "C = 0.01\n",
        "C = 1\n",
        "C = 100 \n",
        "\n",
        "gamma = 0.5\n",
        "gamma = 1\n",
        "\n",
        "Em suma:\n",
        "1) Treine as SVMs com o conjunto de treino variando C e gamma;\n",
        "2) Observe o resultado usando o conjunto de validação;\n",
        "3) Indique qual SVM apresenta melhor performance no conjunto de validação. \n",
        "\n",
        "Obs: O produto Cartesiano das opções de hiperparâmetros irá exigir 3 x 2 = 6 treinos de SVMs.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b297c8",
      "metadata": {
        "id": "30b297c8",
        "outputId": "67fe5ea9-2c7d-41ec-c0fd-4b2b31b604d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM com C=0.01, gamma=0.5: validation accuracy = 0.5714285714285714\n",
            "SVM com C=0.01, gamma=1: validation accuracy = 0.5714285714285714\n",
            "SVM com C=1, gamma=0.5: validation accuracy = 0.5714285714285714\n",
            "SVM com C=1, gamma=1: validation accuracy = 1.0\n",
            "SVM com C=100, gamma=0.5: validation accuracy = 1.0\n",
            "SVM com C=100, gamma=1: validation accuracy = 1.0\n",
            "Nº de vetores de suporte: [3 4]\n",
            "Índices das amostras de treino selecionadas como vetores de suporte: [0 1 2 3 4 5 6]\n",
            "Valores dos \"lambdas\": [[-1.         -1.         -1.          0.13719668  0.86280332  1.\n",
            "   1.        ]]\n",
            "Termo independente b: [0.35086436]\n",
            "Melhor SVM: SVC(C=1, gamma=1) com accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregar o conjunto de treinamento e validação\n",
        "train_data = pd.read_csv(r'C:\\Users\\Dell\\Documents\\SIGAA\\8º Semestre\\Inteligência Computacional\\estudante_201706840055_train.txt')\n",
        "\n",
        "val_data = pd.read_csv(r'C:\\Users\\Dell\\Documents\\SIGAA\\8º Semestre\\Inteligência Computacional\\estudante_201706840055_validation.txt')\n",
        "\n",
        "data_train = np.array(df_train)\n",
        "X_train = data_train[:, :-1] \n",
        "y_train = data_train[:, -1] \n",
        "\n",
        "data_val = np.array(df_train)\n",
        "X_val = data_train[:, :-1] \n",
        "y_val = data_train[:, -1] \n",
        "\n",
        "# Normaliza os dados\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_val = sc.transform(X_val)\n",
        "\n",
        "# Valores de C e gamma \n",
        "param_grid = {'C': [0.01, 1, 100], 'gamma': [0.5, 1]}\n",
        "\n",
        "# Loop para treinar as SVMs com os diferentes valores de C e gamma e avaliar a performance no conjunto de validação\n",
        "best_accuracy = 0\n",
        "for C in param_grid['C']:\n",
        "    for gamma in param_grid['gamma']:\n",
        "        svm = SVC(kernel='rbf', C=C, gamma=gamma)\n",
        "        svm.fit(X_train, y_train)\n",
        "        y_pred = svm.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        print(f'SVM com C={C}, gamma={gamma}: validation accuracy = {accuracy}')\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_svm = svm\n",
        "\n",
        "print(f'Nº de vetores de suporte: {best_svm.n_support_}')\n",
        "# Obter os índices das amostras de treino selecionadas como vetores de suporte\n",
        "support_indices = best_svm.support_\n",
        "\n",
        "# Obter os valores dos \"lambdas\" e o termo independente b \n",
        "lambdas = best_svm.dual_coef_\n",
        "bias = best_svm.intercept_\n",
        "\n",
        "print(f'Índices das amostras de treino selecionadas como vetores de suporte: {support_indices}')\n",
        "print(f'Valores dos \"lambdas\": {lambdas}')\n",
        "print(f'Termo independente b: {bias}')\n",
        "\n",
        "# Imprimir a SVM com melhor performance\n",
        "print(f'Melhor SVM: {best_svm} com accuracy = {best_accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36f19724",
      "metadata": {
        "id": "36f19724"
      },
      "source": [
        "b) Descreva totalmente (por extenso) os parâmetros que compõem a fórmula final do classificador SVM escolhido, indicando:\n",
        "\n",
        "b1) Os parâmetros escolhidos do kernel (gamma neste caso, visto que C é apenas um hiperparâmetro, usado no treino mas não no teste) \n",
        "\n",
        "b2) O número de vetores de suporte (SVs)\n",
        "\n",
        "b3) Seus índices no conjunto de treino\n",
        "\n",
        "b4) Os respectivos valores dos “lambdas” (ou “dual_coef_” de coeficientes duais) e \n",
        "\n",
        "b5) O termo independente b chamado de “bias” ou “intercept_”."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5456fc19",
      "metadata": {
        "id": "5456fc19"
      },
      "source": [
        "Resposta:\n",
        "b1) O parâmetro escolhido do kernel é gamma, com valor igual a 1.\n",
        "b2) O número de vetores de suporte é composto por 3 amostras da classe negativa e 4 amostras da classe positiva.\n",
        "b3) Os índices das amostras de treino selecionadas como vetores de suporte são: [0, 1, 2, 3, 4, 5, 6].\n",
        "\n",
        "b4) Os valores dos “lambdas” (ou “dual_coef_” de coeficientes duais) são: [[-1. -1. -1. 0.13719668 0.86280332 1. 1.]].\n",
        "\n",
        "b5) O termo independente b é de 0.35086436."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34cfa667",
      "metadata": {
        "id": "34cfa667"
      },
      "source": [
        "1) A figura abaixo mostra os exemplos de treino e as regiões de decisão de uma SVM (ou SVC, de “support vector classifier”) para um problema binário (duas classes) onde o vetor x de “features” de entrada tem dois parâmetros (weight e length). Os pontos em azul e vermelho, representam os exemplos de cada classe. As regiões em azul e vermelho representam as regiões nas quais o classificador irá prever uma classe azul e vermelha, respectivamente. Olhando para as figuras, informe: \n",
        "\n",
        "a) Quantos erros cada SVM possui no conjunto de treino ? \n",
        "b) Qual a que lhe parece ser a melhor SVM? Por que?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72d4373",
      "metadata": {
        "id": "e72d4373"
      },
      "source": [
        "Resposta:\n",
        "a) Com excessão da SVC with polynomial kernel,que não há erro, e da LinearSVC, com 2 erros, todas possuem 1 erro no conjunto de treino.\n",
        "b) A melhor parece ser a SVC with linear kernel. Pois nela as regiões de decisão estão bem afastadas umas das outras. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d53f62",
      "metadata": {
        "id": "37d53f62"
      },
      "source": [
        "2) A regularização é uma importante ferramenta para controlar a “complexidade do modelo” durante a fase de seu projeto. No projeto de uma SVM, o hiperparâmetro C é usado para efetuar a regularização do modelo na etapa de seleção do modelo, ou seja, quando os hiperparâmetros são variados e observamos o impacto através do erro de classificação no conjunto de validação. Suponha que você se encontra em uma situação onde está descontente com o atual resultado de sua SVM e observa que o número de vetores de suporte está relativamente pequeno. Você quer potencialmente aumentar o número de vetores de suporte, fazendo com que sua nova SVM seja um modelo mais “complexo”. Para isso, você deve aumentar ou diminuir o parâmetro “C” da classe SVC do scikit-learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db09520a",
      "metadata": {
        "id": "db09520a"
      },
      "source": [
        "Para aumentar o número de vetores de suporte, o parâmetro C deve ser diminuído. Isso ocorre porque o parâmetro C controla a margem da SVM, e quanto maior o valor de C, menor será a margem e maior será a penalidade por classificações incorretas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2065e989",
      "metadata": {
        "id": "2065e989"
      },
      "source": [
        "3) Um classificador usa vetores de entrada com dimensão K=5 “features”. Após treinar uma SVM linear, o número de vetores de suporte foi de 450 exemplos. Neste caso, calcular o kernel linear corresponde a um produto interno entre dois vetores de dimensão K=5, cada, o que requer K multiplicações e K-1 adições. Estime o fator F = Coriginal / Cperceptron de redução do custo computacional da etapa de teste ao converter esta SVM linear para um perceptron. Assuma que os custos Coriginal e Cperceptron correspondem ao número de multiplicações e adições usando-se, respectivamente, a SVM original com os 450 vetores de suporte e após sua conversão para perceptron."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1bc135",
      "metadata": {
        "id": "de1bc135"
      },
      "source": [
        "Para a SVM linear, precisamos calcular o produto interno entre o vetor de entrada e cada um dos 450 vetores de suporte. Isso requer 450 operações de produto escalar, cada um dos quais envolve 5 multiplicações e 4 adições, totalizando \n",
        "\n",
        "C(original) = 450 * 5 * 4 = 9.000 operações de multiplicação e adição.\n",
        "\n",
        "Para o perceptron, precisamos calcular o produto interno entre o vetor de entrada e o vetor de pesos. Isso requer 5 multiplicações e 4 adições, totalizando\n",
        "\n",
        "C(perceptron) = 5 * 4 = 20 operações de multiplicação e adição.\n",
        "\n",
        "F = C(original) / C(perceptron) = (9.000 operações) / (20 operações) ≈ 450\n",
        "\n",
        "Da SVM linear para um perceptron reduz o custo computacional de avaliação por um fator de aproximadamente 450"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6913bcb8",
      "metadata": {
        "id": "6913bcb8"
      },
      "source": [
        "4) Interpretação do resultado de projeto de SVMs.\n",
        "O treinamento de uma SVM linear usando a classe SVC do sklearn retornou o resultado:\n",
        "svm.n_support_= [1 2]  # número de vetores de suporte por classe\n",
        "svm.support_vectors_= \t[[ 1. 4.]  # vetores de suporte\n",
        " [-2.  3.]\n",
        " [-2. -5.]]\n",
        "svm.dual_coef_= [[-0.5 -0.3 0.8]] # valores de \\lambda\n",
        "svc.intercept_= [-2] # “bias”\n",
        "Observe que esta questão não usa o conjunto de treino indicado, mas outro. Pede-se:\n",
        "a) A função de decisão para essa SVM de acordo com a fórmula geral:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddcc3d5d",
      "metadata": {
        "id": "ddcc3d5d"
      },
      "source": [
        "fórmula geral:\n",
        "\n",
        "f(z) = (Σ lambda_i * K(z,x_i)) + b\n",
        "Substituindo os valores dados na questão:\n",
        "\n",
        "f(z) = (-0.5K(z,[1,4])) + (-0.3K(z,[-2,3])) + (0.8*K(z,[-2,-5])) - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d0c5ae",
      "metadata": {
        "id": "94d0c5ae"
      },
      "source": [
        "b) A função de decisão desta SVM quando escrita como um perceptron f(z)=<z,w>+b.\n",
        "c) A saída da função de decisão quando o vetor de entrada é z=[0, 0] e o respectivo rótulo predito y assumindo-se que y = I( f(z) > 0 ), onde I(.) é a função “indicador”, que é 1 se o argumento é verdadeiro, ou 0 em caso contrário.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4a5c90",
      "metadata": {
        "id": "1f4a5c90"
      },
      "source": [
        "b)\n",
        "f(z) = <z, w> + b\n",
        "Primeiro, é preciso calcular os valores de w multiplicando os valores dos vetores de suporte pelos valores de lambda:\n",
        "w = Σ lambda_i * x_i\n",
        "\n",
        "w = (-0.5 * [1, 4]) + (-0.3 * [-2, 3]) + (0.8 * [-2, -5])\n",
        "w = [1.1, 2.9]\n",
        "b= -2\n",
        "\n",
        "função de decisão da SVM quando escrita como um perceptron é:\n",
        "f(z) = <z, [1.1, 2.9]> - 2\n",
        "\n",
        "\n",
        "c)\n",
        "Substituindo o valor de z=[0,0]\n",
        "\n",
        "f([0,0]) = (0.5 * (01 + 04)) + (-0.3 * (0*(-2) + 03)) + (0.8 * (0(-2) + 0*(-5))) - 2 \n",
        "= -2\n",
        "Como f([0,0]) não é maior do que zero, temos que y = I(f([0,0])) = 0. Portanto, o rótulo predito para o vetor de entrada z=[0,0] é 0."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bfa428f",
      "metadata": {
        "id": "0bfa428f"
      },
      "source": [
        "5) Interpretação do resultado de projeto de SVMs.\n",
        "O código ak_svm_prova1.py e o conjunto de treino em dataset_train.txt foram usados para gerar a figura e o log (saída de texto) abaixo. Em suma, foram treinadas 4 SVMs, duas com kernel linear (SVMs 1 e 2) e outras duas com kernel não-linear (SVMs 3 e 4). \n",
        "Pergunta-se:\n",
        "a) Quais as expressões para as SVMs 3 e 4 (não-lineares) e para a SVM 2 (linear) de acordo com a nomenclatura abaixo (escreva a “fórmula” da função de decisão de cada SVM indicando o valor do bias “b”, etc., considerando que z e xn são vetores já normalizados (com o primeiro elemento dividido por 1000).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ba1892c",
      "metadata": {
        "id": "7ba1892c"
      },
      "source": [
        "Para a SVM 2\n",
        "\n",
        "f(z) = (-0.68611287 * z[0] - 0.10653139 * z[1]) - 0.99556119\n",
        "\n",
        "Para a SVM 3 (RBF)\n",
        "\n",
        "f(z) = (-0.91722233 * K(z,x0) - 0.91351914 * K(z,x1) - 0.91300432 * K(z,x2) + 0.87185969 * K(z,x3) + 0.8718861 * K(z,x4) + 1 * K(z,x5)) - 0.08676121\n",
        "\n",
        "Para a SVM 4\n",
        "\n",
        "f(z) = (-0.00887134 * K(z,x0) - 0.03133903 * K(z,x1) + 0.04021037 * K(z,x2)) - 1.03731897"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "936824c7",
      "metadata": {
        "id": "936824c7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0b319212",
      "metadata": {
        "id": "0b319212"
      },
      "source": [
        "Para SVM 1\n",
        "f(z) = <z, w> + b = (-0.686) * (z[0]/1000) + (-0.107) * (z[1]/1000) - 0.996\n",
        "\n",
        "Para SVM 2\n",
        "f(z) = <z, w> + b = (-1.200) * (z[0]/1000) + (-0.200) * (z[1]/1000) - 1.800"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dddc824",
      "metadata": {
        "id": "9dddc824"
      },
      "source": [
        "c) Suponha que para a SVM 2 (linear), apenas as informações abaixo fossem fornecidas. Com elas, você já pôde escrever essa SVM no formato geral de uma SVM, como no item a). Explique agora com clareza quais os passos que você adotaria para converter essa SVM linear em um perceptron como descrito no item b) e indique em termos do número de multiplicações e adições, qual economia no custo computacional que a implementação como perceptron alcança."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faeeecaa",
      "metadata": {
        "id": "faeeecaa"
      },
      "source": [
        "Para converter a SVM linear em um perceptron, é necessário obter os valores dos pesos (w)\n",
        "w = Σ lambda_i * x_i\n",
        "\n",
        "w = (-0.45994152 * [0, -4]) + (-0.27992202 * [-1, 2]) + (0.73986354 * [-2, -2]) = [1.06045492, -3.52044158]\n",
        "b= -1,79\n",
        "\n",
        "f(z) = <z, [1.06045492, -3.52044158]> - 1.79"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d45473d",
      "metadata": {
        "id": "8d45473d"
      },
      "source": [
        "d) Para as SVMs 3 e 4 (não-lineares), indique:\n",
        "d.1) qual o número total de vetores de suporte (SVs), considerando todas as classes.\n",
        "d.2) Quais os índices desses SVs no conjunto de treino e os respectivos valores dos “lambdas” (coeficientes duais)\n",
        "d.3) Qual o valor do termo independente b chamado de “bias” ou “intercept_”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9979a83",
      "metadata": {
        "id": "b9979a83"
      },
      "source": [
        "Para a SVM 3:\n",
        "d1) O número total de vetores de suporte é 6.\n",
        "d2) Os índices dos SVs são [0, 1, 2, 3, 4, 5] e os respectivos valores de lambdas são [-0.91722233, -0.91351914, -0.91300432, 0.87185969, 0.8718861, 1.0].\n",
        "d3) O valor de b é -0.08676121.\n",
        "\n",
        "Para a SVM 4:\n",
        "d1) O número total de vetores de suporte é 3 (2 para a primeira classe e 1 para a segunda classe).\n",
        "d2) Os índices dos SVs são [0, 1, 5] e os respectivos valores de lambdas são [-0.00887134, -0.03133903, 0.04021037].\n",
        "d3) O valor de b é -1.03731897."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaecac30",
      "metadata": {
        "id": "aaecac30"
      },
      "source": [
        "e) Considerando as saídas da SVM abaixo para o conjunto de treino, em qual dos exemplos de treino esta SVM está menos “confiante” (assumindo que esses números são “confidence scores”) em sua decisão e qual é a classe que esta SVM prediz para este exemplo?\n",
        "svm.decision_function(X)= [-1.00027976 -1.00027976 -0.99977173  1.00010297  1.00022828  0.90993821]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91351bab",
      "metadata": {
        "id": "91351bab"
      },
      "source": [
        "A SVM está menos \"confiante\" em sua decisão no terceiro exemplo de treino, que recebeu um score de decisão de -0.99977173.\n",
        "A SVM prediz a classe  para o quinto exemplo de treino"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}